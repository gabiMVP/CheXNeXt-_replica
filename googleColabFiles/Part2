    strategy = tf.distribute.MirroredStrategy()
    BATCH_SIZE = BATCH_SIZE * strategy.num_replicas_in_sync

    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))
    print(BATCH_SIZE)
    trainModel = True
    downloadAndPrepareWorkspace()
    imagePrefix = "./images/"
    df = pd.read_csv('./metadata/Data_Entry_2017_v2020UPDATED.csv', usecols=[0, 1])
    df['Image Index'] = imagePrefix + df['Image Index'].astype(str)
    y_entry = df.pop('Finding Labels')
    y = y_entry.str.get_dummies()
    y.pop('No Finding')
    df = pd.concat([df, y], axis=1)
    columns = df.columns.values
    X_train, X_test, Y_train, Y_test = train_test_split(df[columns[0]], df[columns[1:]], test_size=0.2, shuffle=False)
    # test for 1
    # loadImageAndPreprocess(X_train[0],None)
    # readPixel(X_train[0])
    option_no_order = tf.data.Options()
    option_no_order.experimental_deterministic = False
    # Train
    trainDataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))
    # trainDataset = trainDataset.with_options(option_no_order)
    trainDataset = trainDataset.map(loadImageAndPreprocess, num_parallel_calls=AUTO)
    trainDataset = trainDataset.shuffle(2000)
    # drop_remainder is important on TPU, batch size must be fixed
    trainDataset = trainDataset.batch(BATCH_SIZE, drop_remainder=True)
    trainDataset = trainDataset.prefetch(AUTO)

    # Test
    testDataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))
    testDataset = testDataset.map(loadImageAndPreprocess, num_parallel_calls=AUTO)
    # drop_remainder is important on TPU, batch size must be fixed
    testDataset = testDataset.batch(BATCH_SIZE, drop_remainder=True)
    testDataset = testDataset.prefetch(AUTO)
    Y_train = Y_train.to_numpy()

    # since we have multi label we sum per axis 0 argmax is incorect
    totalsPerDisease = np.sum(Y_train, axis=0)
    total = np.sum(totalsPerDisease)
    # formula per weight :  n_samples / (n_classes * np.bincount(y))
    weights = total / (len(CLASS_NAMES) * totalsPerDisease)

    class_weights = dict(enumerate(weights))
    with strategy.scope():
      model = define_compile_model()
    model.summary()
    # model.load_weights(filepath="checkpoint/model.20-0.8029_bestRecall.h5")
    EPOCHS = 20

    steps_per_epoch = math.floor(len(X_train) / BATCH_SIZE)
    validation_steps = math.floor(len(X_test) / BATCH_SIZE)

    reduce_lr_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.5,
                                          patience=3, verbose=1, min_lr=0.00001)
    checkpoint_filepath = './checkpoint/'


    class_weights = None
    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
        filepath='./checkpoint/model.{epoch:02d}-{val_auc:.4f}.h5',
        save_weights_only=True,
        monitor='val_auc',
        mode='max',
        verbose=1,
        save_best_only=False)
    if trainModel:
        history = model.fit(
            trainDataset, steps_per_epoch=steps_per_epoch, validation_data=testDataset,
            validation_steps=validation_steps, epochs=30,
            callbacks=[reduce_lr_plateau,model_checkpoint_callback], class_weight=class_weights
        )
        model.save("CheXnetXt_replica_gabi")
    else:

        evaluate = True
        if evaluate:
            eval = model.predict(testDataset, steps=validation_steps)
            results = model.evaluate(testDataset, steps=validation_steps, verbose=2)
            for name, value in zip(model.metrics_names, results):
                print(name, ': ', value)
            # images, labels = tuple(zip(*testDataset))
            # labels = np.array(labels)
            # y = np.concatenate([y for x, y in testDataset], axis=0)
            testLabels = Y_test
            testLabels = tf.convert_to_tensor(testLabels).numpy()
            plot_cm(testLabels, eval)
            multiclass_roc_auc_score(testLabels, eval)
        idx = 660
        df2 = pd.read_csv('./metadata/Old/BBox_List_2017 (1).csv')
        row = df2.iloc[idx]
        actual_label = convertfromNameOfDiseazeToOneHot(row[1])
        image_path = "./images/" + row[0]

        vizualizeCam(actual_label, model, image_path, np.array(row[2:6].tolist()))
   
